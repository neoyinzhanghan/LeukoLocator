{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/angelopoulos/miniconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "from scipy.optimize import brentq\n",
    "from scipy.stats import binom\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import random\n",
    "import pdb\n",
    "import csv\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataFrame Columns:\n",
    "\n",
    "`probs`: A column containing lists or arrays of probabilities. Each element in the probs column should be an iterable (like a list or a numpy array) with probabilities corresponding to different classes. This is inferred because the function uses row['probs'].max() and row['probs'].argmax(), which are operations performed on lists or arrays to find the maximum value and the index of the maximum value, respectively.\n",
    "\n",
    "`label_numeric`: A numeric label for each observation. This column is used to compute whether the predictions (yhat) are correct compared to the actual labels.\n",
    "\n",
    "# Parameters Dictionary (params):\n",
    "`This` function also uses a dictionary named params that is expected to include specific keys:\n",
    "\n",
    "`n`: An integer specifying the number of observations to consider in some calculations or operations. If a validation DataFrame (val_df) is not provided, this parameter likely defines how the DataFrame is split into calibration and validation sets.\n",
    "\n",
    "`alpha`: This parameter is referenced, but its use in the function is not directly visible from the code snippet. It could be part of further calculations not shown here.\n",
    "\n",
    "`delta`: Similar to alpha, its usage isn't directly observed but is expected to play a role perhaps in subsequent calculations or conditions.\n",
    "\n",
    "`lambda_max` and lambda_min: These parameters define the range for creating a grid of lambda values (lambdas) which could be used for regularization or other calculations in extended parts of the function.\n",
    "\n",
    "`N_lambda`: The number of lambda values to generate within the specified range from lambda_min to lambda_max."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_randomness(seed=0):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "def get_selective_results(df, name, params, val_df=None):\n",
    "    # Unpack the parameters\n",
    "    if val_df is not None:\n",
    "        cal_df = df.copy(deep=True)\n",
    "        params['n'] = len(cal_df)\n",
    "    n, alpha, delta, lambda_max, lambda_min, N_lambda = (params[k] for k in ('n', 'alpha', 'delta', 'lambda_max', 'lambda_min', 'N_lambda'))\n",
    "    \n",
    "    # If only one dataframe is passed, split into cal/val\n",
    "    if val_df is None:\n",
    "        fix_randomness()\n",
    "        val_df = df.sample(n=len(df)-n)\n",
    "        cal_df = df.drop(val_df.index)\n",
    "    \n",
    "    # Define lambda grid\n",
    "    lambdas = np.linspace(lambda_min, lambda_max, N_lambda)\n",
    "    \n",
    "    # Unpack the labels, probs, and estimated labels\n",
    "    cal_df['max_prob'] = cal_df.apply(lambda row: row['probs'].max(), axis=1)\n",
    "    cal_df['yhat'] = cal_df.apply(lambda row: row['probs'].argmax(), axis=1)\n",
    "    cal_labels = cal_df['label_numeric'].squeeze()\n",
    "    cal_phats = cal_df['max_prob']\n",
    "    cal_yhats = cal_df['yhat']\n",
    "    cal_corrects = (cal_yhats == cal_labels)\n",
    "    \n",
    "    val_df['max_prob'] = val_df.apply(lambda row: row['probs'].max(), axis=1)\n",
    "    val_df['yhat'] = val_df.apply(lambda row: row['probs'].argmax(), axis=1)\n",
    "    val_labels = val_df['label_numeric'].squeeze()\n",
    "    val_phats = val_df['max_prob']\n",
    "    val_yhats = val_df['yhat']\n",
    "    val_corrects = (val_yhats == val_labels)\n",
    "    \n",
    "    results = {\n",
    "        'labels' : [np.unique(np.concatenate([cal_labels, val_labels]))],\n",
    "        'label counts (cal)' : [np.unique(cal_labels,return_counts=True)[1]],\n",
    "        'label counts (val)' : [np.unique(val_labels,return_counts=True)[1]],\n",
    "        'accuracy (cal, before selection)' : cal_corrects.mean(),\n",
    "        'accuracy (val, before selection)' : val_corrects.mean(),\n",
    "        'dataset size (cal)' : cal_yhats.shape[0],\n",
    "        'dataset size (val)' : val_yhats.shape[0],\n",
    "    }\n",
    "    results.update(params)\n",
    "    \n",
    "    \n",
    "    # Define selective risk\n",
    "    def selective_error(lam): return 1-cal_corrects[cal_phats > lam].mean()\n",
    "    def nlambda(lam): return (cal_phats > lam).sum()\n",
    "    lambdas_trunc = np.array([lam for lam in lambdas if nlambda(lam) >= 50]) # Make sure there's some data in the top bin.\n",
    "    def invert_for_ub(r,lam): return binom.cdf(selective_error(lam)*nlambda(lam),nlambda(lam),r)-delta\n",
    "    # Construct upper bound\n",
    "    def selective_risk_ub(lam): return brentq(invert_for_ub,0,0.9999,args=(lam,))\n",
    "    # Scan to choose lamabda hat\n",
    "    for lhat in np.flip(lambdas_trunc):\n",
    "        if selective_risk_ub(lhat-1/lambdas_trunc.shape[0]) > alpha: break\n",
    "    if lhat == lambdas_trunc[-1]:\n",
    "        raise Exception(\"This level is too stringent!\")\n",
    "    # Deploy procedure on test data\n",
    "    predictions = val_phats >= lhat\n",
    "    \n",
    "    # Calculate initial metrics\n",
    "    results['number correct (cal, predicted)'] = cal_corrects[cal_phats >= lhat].sum()\n",
    "    results['number incorrect (cal, predicted)'] = (1-cal_corrects.astype(int))[cal_phats >= lhat].sum()\n",
    "    results['number correct (cal, abstained)'] = cal_corrects[cal_phats < lhat].sum()\n",
    "    results['number incorrect (cal, abstained)'] = (1-cal_corrects.astype(int))[cal_phats < lhat].sum()\n",
    "    results['number correct (val, predicted)'] = val_corrects[predictions].sum()\n",
    "    results['number incorrect (val, predicted)'] = (1-val_corrects.astype(int))[predictions].sum()\n",
    "    results['number correct (val, abstained)'] = val_corrects[val_phats < lhat].sum()\n",
    "    results['number incorrect (val, abstained)'] = (1-val_corrects.astype(int))[val_phats < lhat].sum()\n",
    "    results['lambda_hat'] = lhat\n",
    "\n",
    "    # Pretty-print and save results\n",
    "    base_folder = './results/' + name + '/'\n",
    "    os.makedirs(base_folder, exist_ok = True)\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df = results_df.to_csv(base_folder + 'results.csv', index=False)\n",
    "    print(tabulate(results_df))\n",
    "    \n",
    "    # Make plots\n",
    "    sns.set(style='white')\n",
    "    accuracy_selected = [val_corrects[val_phats > lam].mean() for lam in lambdas]\n",
    "    fraction_selected = [(val_phats > lam).mean() for lam in lambdas]\n",
    "    fraction_correct_points_selected = [val_corrects[val_phats > lam].sum()/val_corrects.sum() for lam in lambdas]\n",
    "    # Make plots non-overlapping\n",
    "    xlims = [0, None]\n",
    "    plt.figure()\n",
    "    plt.plot(lambdas,accuracy_selected,label='all',color='#2222AA',linewidth=2)\n",
    "    plt.gca().axhline(y=1-alpha,linewidth=1.5,linestyle='dotted',label=r'target accuracy ($1-\\alpha$)',color='gray')\n",
    "    plt.gca().axvline(x=lhat,linewidth=1.5,linestyle='--',label=r'$\\hat{\\lambda}$',color='gray')\n",
    "    sns.despine(top=True,right=True)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.xlabel(r'$\\lambda$')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlim(xlims)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(base_folder + 'accuracy_vs_lambda.pdf')\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(lambdas,fraction_selected,color='#DD5500', linewidth=2)\n",
    "    plt.gca().axvline(x=lhat,linewidth=1.5,linestyle='--',label=r'$\\hat{\\lambda}$',color='gray')\n",
    "    sns.despine(top=True,right=True)\n",
    "    plt.legend(loc='lower left')\n",
    "    plt.xlabel(r'$\\lambda$')\n",
    "    plt.ylabel('fraction selected of total val')\n",
    "    plt.xlim(xlims)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(base_folder + 'fraction_predicted_vs_lambda.pdf')\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(lambdas,fraction_correct_points_selected,color='#AA22AA', linewidth=2)\n",
    "    plt.gca().axvline(x=lhat,linewidth=1.5,linestyle='--',label=r'$\\hat{\\lambda}$',color='gray')\n",
    "    sns.despine(top=True,right=True)\n",
    "    plt.legend(loc='lower left')\n",
    "    plt.xlabel(r'$\\lambda$')\n",
    "    plt.ylabel('fraction selected of total correct')\n",
    "    plt.xlim(xlims)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(base_folder + 'correct_points_predicted_over_total_correct_vs_lambda.pdf')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process dataframe\n",
    "def process_df(df, institution=None, abnormal=None, specimen_type=None, scanner=None, split=None):\n",
    "    proc_df = df.copy(deep=True) #Create a copy df to modify\n",
    "    # Get softmax score of every class\n",
    "    cols = list(proc_df.columns)\n",
    "    cols = [col for col in cols if 'prob_' in col]\n",
    "    label_to_num = {\n",
    "        cols[i].split('prob_')[1] : i for i in range(len(cols))\n",
    "    }\n",
    "    proc_df['probs'] = proc_df.apply(lambda row: np.array([row[col] for col in cols]), axis=1)\n",
    "    # Remove or rename junk classes\n",
    "    #proc_df['label'] = proc_df['label'].replace('MO3', 'MO2')\n",
    "    proc_df = proc_df[~proc_df.label.isin(['U2', 'MO3'])]\n",
    "    # Create numeric labels for every class\n",
    "    proc_df['label_numeric'] = proc_df.apply(lambda row: label_to_num[row['label']], axis=1)\n",
    "    # Stratify\n",
    "    if institution is not None: # Possible values: MSKCC, UCSF\n",
    "        proc_df = proc_df[proc_df.institution.isin(institution)]\n",
    "    if abnormal is not None: # Possible values: True, False\n",
    "        proc_df = proc_df[proc_df.abnormal.isin(abnormal)]\n",
    "    if specimen_type is not None: # Possible values: PB, BMA\n",
    "        proc_df = proc_df[proc_df.specimen_type.isin(specimen_type)]\n",
    "    if scanner is not None: # Possible values: Aperio, Hamamatsu\n",
    "        proc_df = proc_df[proc_df.scanner.isin(scanner)]\n",
    "    if split is not None: # Possible values: Train, Test, Val\n",
    "        proc_df = proc_df[proc_df.split.isin(split)]\n",
    "    if len(proc_df) == 0:\n",
    "        raise Exception(\"There are no data points in this stratum!\")\n",
    "\n",
    "    return proc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('labeled_cells.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Experiment 1: Random split UCSF.\n",
    "params = {\n",
    "    'n' : 5000, # Will be overwritten if we manually input a cal/val set.\n",
    "    'alpha' : 0.05,\n",
    "    'delta' : 0.2,\n",
    "    'lambda_max' : 1,\n",
    "    'lambda_min' : 0,\n",
    "    'N_lambda' : 5000,\n",
    "}\n",
    "total_df = process_df(df, institution=['UCSF'], split=['val','test'])\n",
    "name = 'UCSF-val-test-random-split'\n",
    "get_selective_results(total_df, name, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Experiment 2: Random split MSKCC normal.\n",
    "params = {\n",
    "    'n' : 1500, # Will be overwritten if we manually input a cal/val set.\n",
    "    'alpha' : 0.08,\n",
    "    'delta' : 0.2,\n",
    "    'lambda_max' : 1,\n",
    "    'lambda_min' : 0,\n",
    "    'N_lambda' : 5000,\n",
    "}\n",
    "total_df = process_df(df, institution=['MSKCC'], specimen_type=['BMA'], abnormal=[False])\n",
    "name = 'MSKCC-normal-bma-random-split'\n",
    "get_selective_results(total_df, name, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Experiment 3: Random split MSKCC abnormal.\n",
    "params = {\n",
    "    'n' : 1500, # Will be overwritten if we manually input a cal/val set.\n",
    "    'alpha' : 0.08,\n",
    "    'delta' : 0.2,\n",
    "    'lambda_max' : 1,\n",
    "    'lambda_min' : 0,\n",
    "    'N_lambda' : 5000,\n",
    "}\n",
    "total_df = process_df(df, institution=['MSKCC'], specimen_type=['BMA'], abnormal=[True])\n",
    "name = 'MSKCC-abnormal-bma-random-split'\n",
    "get_selective_results(total_df, name, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Experiment 4: Random split MSKCC PB.\n",
    "params = {\n",
    "    'n' : 1000, # Will be overwritten if we manually input a cal/val set.\n",
    "    'alpha' : 0.08,\n",
    "    'delta' : 0.2,\n",
    "    'lambda_max' : 1,\n",
    "    'lambda_min' : 0,\n",
    "    'N_lambda' : 5000,\n",
    "}\n",
    "total_df = process_df(df, institution=['MSKCC'], specimen_type=['PB'])\n",
    "name = 'MSKCC-abnormal-pb-random-split'\n",
    "get_selective_results(total_df, name, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method was first introduced in https://arxiv.org/abs/2110.01052."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
